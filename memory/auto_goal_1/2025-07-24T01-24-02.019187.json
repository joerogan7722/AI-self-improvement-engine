{
  "cycle": null,
  "goal_id": "auto_goal_1",
  "description": "Improve refactoring: Found 1 code smells requiring attention",
  "current_code": "# File: src/ai_self_ext_engine/roles/refine.py\nfrom typing import List, TYPE_CHECKING\nfrom pathlib import Path\nimport subprocess\nimport os\nimport logging\nimport re  # Added import for regex\nfrom ai_self_ext_engine.core.role import Role, Context\nfrom ai_self_ext_engine.model_client import ModelClient, ModelCallError\nfrom ai_self_ext_engine.config import MainConfig\nfrom ai_self_ext_engine.learning_log import LearningLog\n\n\nif TYPE_CHECKING:\n    from ai_self_ext_engine.todo_schema import Todo\n\n\nlogger = logging.getLogger(__name__)\n\n\nclass RefineRole(Role):\n    def __init__(\n        self,\n        config: MainConfig,\n        model_client: ModelClient,\n        learning_log: LearningLog,\n    ):\n        self.config = config\n        self.model_client = model_client\n        self.learning_log = learning_log\n        self.prompt_template_path = (\n            Path(config.engine.prompts_dir) / \"patch_generation.tpl\"\n        )\n\n    def run(self, context: Context) -> Context:\n        if not context.todos:\n            logger.info(\"RefineRole: No todos in context. Skipping.\")\n            return context\n\n        logger.info(\n            \"RefineRole: Generating and applying patch for todos: %s\",\n            context.todos,\n        )\n\n        try:\n            # Read code for each todo and combine\n            code_context_for_llm = self._read_code_for_todos(context.todos)\n            context.current_code = code_context_for_llm  # Update context\n\n            # Load prompt template from file\n            if not self.prompt_template_path.exists():\n                raise FileNotFoundError(\n                    f\"Prompt template not found at {self.prompt_template_path}\"\n                )\n\n            prompt_template = self.prompt_template_path.read_text(\n                encoding=\"utf-8\"\n            )\n\n            # Format todos for the prompt\n            todos_formatted = \"\\n\".join(\n                [\n                    f\"- File: {todo.get('file_path', 'N/A')}, \"\n                    f\"Type: {todo.get('change_type', 'modify')}, \"\n                    \"Description: \"\n                    f\"{todo.get('description', 'No description')}\"\n                    for todo in context.todos\n                ]\n            )\n            # Load and format learning examples\n            learning_examples = self._format_learning_examples()\n\n            prompt = prompt_template.format(\n                current_code=code_context_for_llm,\n                todos=todos_formatted,\n                learning_examples=learning_examples,\n            )\n\n            raw_patch_response = self.model_client.call_model(\n                self.config.model.model_name, prompt=prompt\n            ).strip()\n\n            # Extract patch using the new delimiters\n            patch = self._extract_patch_from_response(raw_patch_response)\n\n            context.patch = patch\n            logger.debug(\"RefineRole: Generated patch:\\n%s\", patch)\n\n            if patch:\n                # Normalize line endings and strip trailing whitespace\n                normalized_patch = patch.replace('\\r\\n', '\\n')\n                normalized_patch = '\\n'.join(line.rstrip() for line in normalized_patch.splitlines())\n\n                # Use the actual current working directory as cwd for git apply\n                if self._apply_patch(normalized_patch, os.getcwd()):\n                    logger.info(\"RefineRole: Patch applied successfully.\")\n                else:\n                    logger.error(\"RefineRole: Failed to apply patch. Aborting.\")\n                    context.should_abort = True\n            else:\n                logger.info(\"RefineRole: No valid patch generated. Skipping application.\")\n                context.should_abort = True # Abort if no patch is generated for existing todos\n\n        except ModelCallError as e:\n            logger.error(\"RefineRole: Model call error: %s\", e)\n            context.should_abort = True\n        except Exception as e:\n            logger.exception(\"RefineRole: An unexpected error occurred: %s\", e)\n            context.should_abort = True\n\n        return context\n\n    def _extract_patch_from_response(self, response_text: str) -> str:\n        \"\"\"\n        Extracts the unified diff patch string from the LLM's response,\n        with improved handling of various formats.\n        \"\"\"\n        # Try multiple extraction patterns\n        patterns = [\n            r\"```diff\\n(.*?)\\n```\",  # Standard diff format\n            r\"```patch\\n(.*?)\\n```\", # Alternative patch format  \n            r\"```\\n(.*?)\\n```\",      # Generic code block\n            r\"--- a/(.*?)\\+\\+\\+ b/(.*)\",  # Direct patch detection\n        ]\n        \n        for pattern in patterns:\n            match = re.search(pattern, response_text, re.DOTALL)\n            if match:\n                patch = match.group(1).strip()\n                # Validate that it looks like a patch\n                if ('--- a/' in patch and '+++ b/' in patch) or ('def ' in patch or 'class ' in patch):\n                    return patch\n        \n        # If no standard patch found, try to extract any code-like content\n        if 'def ' in response_text or 'class ' in response_text:\n            # Extract potential Python code additions\n            lines = response_text.split('\\n')\n            code_lines = []\n            in_code = False\n            \n            for line in lines:\n                if 'def ' in line or 'class ' in line:\n                    in_code = True\n                    code_lines.append(f'+{line}')\n                elif in_code and (line.startswith('    ') or line.strip() == ''):\n                    code_lines.append(f'+{line}')\n                elif in_code and not line.startswith('    '):\n                    break\n            \n            if code_lines:\n                # Create a simple patch format for new code\n                return '\\n'.join(code_lines)\n        \n        return \"\"\n\n    def _read_code_for_todos(self, todos: List[\"Todo\"]) -> str:\n        \"\"\"\n        Reads code from files specified in the todos and concatenates them.\n        Only reads files that have a 'file_path' and 'modify' or 'delete'\n        change_type.\n        \"\"\"\n        code_snippets = []\n        for todo in todos:\n            file_path_str = todo.get(\"file_path\")\n            change_type = todo.get(\"change_type\")\n\n            if not file_path_str or change_type == \"add\":\n                # Skip if no file_path or if it's an 'add' operation\n                continue\n\n            # Ensure file_path_str starts with 'src/'\n            if not file_path_str.startswith('src/'):\n                logger.warning(\n                    f\"Invalid file_path in todo: {file_path_str}. Skipping.\"\n                )\n                continue\n\n            # Construct the absolute path correctly from the project root\n            # Assuming os.getcwd() is the project root.\n            file_path = Path(os.getcwd()) / file_path_str\n\n            if not file_path.exists():\n                logger.warning(\n                    \"File specified in todo does not exist: %s\", file_path\n                )\n                continue\n\n            try:\n                content = file_path.read_text(encoding=\"utf-8\")\n                # Add file header for context\n                code_snippets.append(f\"# File: {file_path_str}\\n\")\n\n                line_start = todo.get(\"line_start\")\n                line_end = todo.get(\"line_end\")\n\n                if line_start is not None and line_end is not None:\n                    lines = content.splitlines()\n                    # Adjust for 0-based indexing\n                    start_idx = max(0, line_start - 1)\n                    end_idx = min(len(lines), line_end)\n                    code_snippets.append(\n                        \"\\n\".join(lines[start_idx:end_idx])\n                    )\n                else:\n                    code_snippets.append(content)\n                code_snippets.append(\"\\n\\n\")  # Separator\n            except Exception as e:\n                logger.warning(\n                    \"Could not read file %s for todo: %s\", file_path, e\n                )\n        return \"\".join(code_snippets)\n\n    def _format_learning_examples(self) -> str:\n        \"\"\"\n        Loads recent learning entries and formats them for the prompt.\n        \"\"\"\n        entries = self.learning_log.load_entries(max_entries=5)\n        if not entries:\n            return \"No past examples available.\"\n\n        formatted_examples = []\n        for entry in entries:\n            outcome = \"SUCCESS\" if entry[\"success\"] else \"FAILURE\"\n            formatted_examples.append(\n                f\"--- Example: {outcome} ---\\n\"\n                f\"Goal: {entry['goal']}\\n\"\n                f\"Review: {entry['review']}\\n\"\n                f\"Patch:\\n{entry['patch']}\\n\"\n            )\n        return \"\\n\".join(formatted_examples)\n\n    def _apply_patch(self, patch_text: str, cwd: str) -> bool:\n        \"\"\"Applies changes directly by parsing patch and modifying files.\"\"\"\n        if not patch_text:\n            return False\n        \n        try:\n            # Parse the patch to extract file changes\n            file_changes = self._parse_patch_to_changes(patch_text)\n            \n            if not file_changes:\n                logger.error(\"RefineRole: No valid file changes found in patch\")\n                return False\n            \n            # Apply each file change directly\n            for file_path, changes in file_changes.items():\n                if self._apply_file_changes(file_path, changes, cwd):\n                    logger.info(f\"RefineRole: Successfully applied changes to {file_path}\")\n                else:\n                    logger.error(f\"RefineRole: Failed to apply changes to {file_path}\")\n                    return False\n            \n            return True\n            \n        except Exception as e:\n            logger.error(f\"RefineRole: Error in patch application: {e}\")\n            return False\n\n    def _parse_patch_to_changes(self, patch_text: str) -> dict:\n        \"\"\"Parse patch text into file changes that can be applied directly.\"\"\"\n        file_changes = {}\n        \n        # Split patch by files (look for --- and +++ markers)\n        lines = patch_text.split('\\n')\n        current_file = None\n        changes = []\n        \n        for line in lines:\n            if line.startswith('--- a/'):\n                # Save previous file changes\n                if current_file and changes:\n                    file_changes[current_file] = changes\n                # Start new file\n                current_file = line[6:]  # Remove '--- a/'\n                changes = []\n            elif line.startswith('+++ b/'):\n                continue  # Skip +++ lines\n            elif line.startswith('@@'):\n                continue  # Skip hunk headers for now - just do full replacements\n            elif line.startswith('+') and not line.startswith('+++'):\n                # Addition\n                changes.append(('add', line[1:]))\n            elif line.startswith('-') and not line.startswith('---'):\n                # Deletion  \n                changes.append(('remove', line[1:]))\n            elif line.startswith(' '):\n                # Context line\n                changes.append(('context', line[1:]))\n        \n        # Save final file\n        if current_file and changes:\n            file_changes[current_file] = changes\n            \n        return file_changes\n    \n    def _apply_file_changes(self, file_path: str, changes: list, cwd: str) -> bool:\n        \"\"\"Apply changes directly to a file using robust insertion logic.\"\"\"\n        try:\n            full_path = Path(cwd) / file_path\n            \n            if not full_path.exists():\n                logger.error(f\"RefineRole: File does not exist: {full_path}\")\n                return False\n            \n            # Read current content\n            content = full_path.read_text(encoding='utf-8')\n            lines = content.splitlines()\n            \n            # Extract meaningful additions (code improvements)\n            additions = []\n            for change_type, line_content in changes:\n                if change_type == 'add' and line_content.strip():\n                    # Clean up the line content\n                    clean_line = line_content.rstrip()\n                    if clean_line and not clean_line.startswith('#'):  # Skip comments\n                        additions.append(clean_line)\n            \n            if not additions:\n                logger.info(f\"RefineRole: No meaningful additions found for {file_path}\")\n                return True\n            \n            # Smart insertion strategy based on content type\n            if self._contains_function_or_class(additions):\n                return self._insert_functions_and_classes(full_path, lines, additions)\n            else:\n                return self._insert_code_improvements(full_path, lines, additions)\n                \n        except Exception as e:\n            logger.error(f\"RefineRole: Error applying changes to {file_path}: {e}\")\n            return False\n    \n    def _contains_function_or_class(self, lines: list) -> bool:\n        \"\"\"Check if additions contain function or class definitions.\"\"\"\n        return any('def ' in line or 'class ' in line for line in lines)\n    \n    def _insert_functions_and_classes(self, file_path: Path, original_lines: list, additions: list) -> bool:\n        \"\"\"Insert new functions and classes at appropriate locations.\"\"\"\n        try:\n            # Find insertion point (before last line or after imports)\n            insert_idx = len(original_lines)\n            \n            # Try to find a good insertion point after imports/existing functions\n            for i, line in enumerate(original_lines):\n                if line.strip().startswith('if __name__'):\n                    insert_idx = i\n                    break\n            \n            # Insert with proper spacing\n            new_lines = original_lines[:insert_idx]\n            if new_lines and new_lines[-1].strip():\n                new_lines.append('')  # Add blank line before new code\n            \n            new_lines.append('# AI-generated improvements:')\n            new_lines.extend(additions)\n            \n            if insert_idx < len(original_lines):\n                new_lines.append('')  # Add blank line after new code\n                new_lines.extend(original_lines[insert_idx:])\n            \n            # Write back\n            new_content = '\\n'.join(new_lines)\n            file_path.write_text(new_content, encoding='utf-8')\n            logger.info(f\"RefineRole: Successfully inserted {len(additions)} lines into {file_path}\")\n            return True\n            \n        except Exception as e:\n            logger.error(f\"RefineRole: Error inserting functions/classes: {e}\")\n            return False\n    \n    def _insert_code_improvements(self, file_path: Path, original_lines: list, additions: list) -> bool:\n        \"\"\"Insert general code improvements.\"\"\"\n        try:\n            # For non-function improvements, append at end with documentation\n            new_lines = original_lines[:]\n            \n            if new_lines and new_lines[-1].strip():\n                new_lines.append('')\n            \n            new_lines.append('# AI-generated code improvements:')\n            new_lines.extend(additions)\n            \n            # Write back\n            new_content = '\\n'.join(new_lines)\n            file_path.write_text(new_content, encoding='utf-8')\n            logger.info(f\"RefineRole: Successfully added {len(additions)} improvement lines to {file_path}\")\n            return True\n            \n        except Exception as e:\n            logger.error(f\"RefineRole: Error inserting improvements: {e}\")\n            return False\n\n\n",
  "todos": [
    {
      "file_path": "src/ai_self_ext_engine/roles/refine.py",
      "change_type": "modify",
      "description": "Refactor the primary code refinement method in the `Refine` role by decomposing its responsibilities into smaller, more focused functions to address a found code smell and enhance modularity."
    }
  ],
  "patch": "--- a/src/ai_self_ext_engine/roles/refine.py\n+++ b/src/ai_self_ext_engine/roles/refine.py\n@@ -37,56 +37,17 @@\n         )\n \n         try:\n-            # Read code for each todo and combine\n-            code_context_for_llm = self._read_code_for_todos(context.todos)\n-            context.current_code = code_context_for_llm  # Update context\n-\n-            # Load prompt template from file\n-            if not self.prompt_template_path.exists():\n-                raise FileNotFoundError(\n-                    f\"Prompt template not found at {self.prompt_template_path}\"\n-                )\n-\n-            prompt_template = self.prompt_template_path.read_text(\n-                encoding=\"utf-8\"\n-            )\n-\n-            # Format todos for the prompt\n-            todos_formatted = \"\\n\".join(\n-                [\n-                    f\"- File: {todo.get('file_path', 'N/A')}, \"\n-                    f\"Type: {todo.get('change_type', 'modify')}, \"\n-                    \"Description: \"\n-                    f\"{todo.get('description', 'No description')}\"\n-                    for todo in context.todos\n-                ]\n-            )\n-            # Load and format learning examples\n-            learning_examples = self._format_learning_examples()\n-\n-            prompt = prompt_template.format(\n-                current_code=code_context_for_llm,\n-                todos=todos_formatted,\n-                learning_examples=learning_examples,\n-            )\n-\n-            raw_patch_response = self.model_client.call_model(\n-                self.config.model.model_name, prompt=prompt\n-            ).strip()\n-\n-            # Extract patch using the new delimiters\n-            patch = self._extract_patch_from_response(raw_patch_response)\n-\n+            # 1. Prepare LLM inputs (code context, formatted todos, learning examples, prompt template)\n+            code_context_for_llm, todos_formatted, learning_examples, prompt_template_content = self._prepare_llm_inputs(context.todos)\n+            context.current_code = code_context_for_llm # Update context\n+\n+            # 2. Generate the patch using LLM\n+            patch = self._call_llm_and_extract_patch(code_context_for_llm, todos_formatted, learning_examples, prompt_template_content)\n             context.patch = patch\n-            logger.debug(\"RefineRole: Generated patch:\\n%s\", patch)\n-\n-            if patch:\n-                # Normalize line endings and strip trailing whitespace\n-                normalized_patch = patch.replace('\\r\\n', '\\n')\n-                normalized_patch = '\\n'.join(line.rstrip() for line in normalized_patch.splitlines())\n-\n-                # Use the actual current working directory as cwd for git apply\n-                if self._apply_patch(normalized_patch, os.getcwd()):\n-                    logger.info(\"RefineRole: Patch applied successfully.\")\n-                else:\n-                    logger.error(\"RefineRole: Failed to apply patch. Aborting.\")\n-                    context.should_abort = True\n-            else:\n-                logger.info(\"RefineRole: No valid patch generated. Skipping application.\")\n-                context.should_abort = True # Abort if no patch is generated for existing todos\n-\n+\n+            # 3. Apply the generated patch to the codebase\n+            self._apply_patch_to_codebase(context, patch)\n+\n+        except FileNotFoundError as e:\n+            self._handle_refinement_exception(context, f\"Prompt template not found: {e}\")\n         except ModelCallError as e:\n-            logger.error(\"RefineRole: Model call error: %s\", e)\n-            context.should_abort = True\n+            self._handle_refinement_exception(context, f\"Model call error: {e}\")\n         except Exception as e:\n-            logger.exception(\"RefineRole: An unexpected error occurred: %s\", e)\n-            context.should_abort = True\n+            self._handle_refinement_exception(context, f\"An unexpected error occurred: {e}\", is_critical=True)\n \n         return context\n \n+    def _prepare_llm_inputs(self, todos: List[\"Todo\"]) -> tuple[str, str, str, str]:\n+        \"\"\"\n+        Reads relevant code, loads prompt template, formats todos, and loads learning examples\n+        to prepare all necessary inputs for the LLM call.\n+        \"\"\"\n+        code_context_for_llm = self._read_code_for_todos(todos)\n+\n+        # Load prompt template from file\n+        if not self.prompt_template_path.exists():\n+            raise FileNotFoundError(\n+                f\"Prompt template not found at {self.prompt_template_path}\"\n+            )\n+        prompt_template_content = self.prompt_template_path.read_text(encoding=\"utf-8\")\n+\n+        # Format todos for the prompt\n+        todos_formatted = \"\\n\".join(\n+            [\n+                f\"- File: {todo.get('file_path', 'N/A')}, \"\n+                f\"Type: {todo.get('change_type', 'modify')}, \"\n+                \"Description: \"\n+                f\"{todo.get('description', 'No description')}\"\n+                for todo in todos\n+            ]\n+        )\n+        # Load and format learning examples\n+        learning_examples = self._format_learning_examples()\n+\n+        return code_context_for_llm, todos_formatted, learning_examples, prompt_template_content\n+\n+    def _call_llm_and_extract_patch(self, current_code: str, todos_formatted: str, learning_examples: str, prompt_template_content: str) -> str:\n+        \"\"\"\n+        Constructs the final prompt using prepared inputs, calls the language model,\n+        and extracts the unified diff patch from the model's response.\n+        \"\"\"\n+        prompt = prompt_template_content.format(\n+            current_code=current_code,\n+            todos=todos_formatted,\n+            learning_examples=learning_examples,\n+        )\n+\n+        raw_patch_response = self.model_client.call_model(\n+            self.config.model.model_name, prompt=prompt\n+        ).strip()\n+\n+        patch = self._extract_patch_from_response(raw_patch_response)\n+        logger.debug(\"RefineRole: Generated patch:\\n%s\", patch)\n+        return patch\n+\n+    def _apply_patch_to_codebase(self, context: Context, patch: str) -> None:\n+        \"\"\"\n+        Normalizes the given patch string and applies it to the codebase.\n+        Updates the context's 'should_abort' flag based on the success of the patch application.\n+        \"\"\"\n+        if patch:\n+            # Normalize line endings and strip trailing whitespace\n+            normalized_patch = patch.replace('\\r\\n', '\\n')\n+            normalized_patch = '\\n'.join(line.rstrip() for line in normalized_patch.splitlines())\n+\n+            if self._apply_patch(normalized_patch, os.getcwd()):\n+                logger.info(\"RefineRole: Patch applied successfully.\")\n+            else:\n+                logger.error(\"RefineRole: Failed to apply patch. Aborting.\")\n+                context.should_abort = True\n+        else:\n+            logger.info(\"RefineRole: No valid patch generated. Skipping application.\")\n+            context.should_abort = True # Abort if no patch is generated for existing todos\n+\n+    def _handle_refinement_exception(self, context: Context, message: str, is_critical: bool = False) -> None:\n+        \"\"\"\n+        Logs an error message (and potentially the full exception traceback for critical errors)\n+        and sets context.should_abort to True.\n+        \"\"\"\n+        if is_critical:\n+            logger.exception(f\"RefineRole: {message}\")\n+        else:\n+            logger.error(f\"RefineRole: {message}\")\n+        context.should_abort = True\n+\n     def _extract_patch_from_response(self, response_text: str) -> str:\n         \"\"\"\n         Extracts the unified diff patch string from the LLM's response,\n         with improved handling of various formats.\n         \"\"\"",
  "test_results": null,
  "accepted": false,
  "should_abort": true,
  "metadata": {}
}